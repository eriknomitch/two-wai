{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe5a50-3bea-4015-8b9e-e1f906d68180",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580c2f95-95dd-43c7-a36e-ddc931bc34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d029a76d-7515-4f5a-8182-9c2561816ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if INSTALL:\n",
    "    ! pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ed0d0e-6201-40b0-8f68-fb8b1237007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41e50c-7c77-4083-96c0-0e26c92fa733",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fbbe4a-da6a-4679-ac1e-2a84303f1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_SIZE = \"tiny\"\n",
    "DEFAULT_DELAY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80132694-5624-43f5-8a0e-343c4bc75c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import whisper\n",
    "from whisper import tokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac72ba7-562e-4119-8b60-68e0274eac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_size = DEFAULT_MODEL_SIZE\n",
    "model = whisper.load_model(current_size)\n",
    "audio_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1832983e-3d2d-46ea-b3c8-e8327f3b1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript(model, audio_chunks):\n",
    "    if len(audio_chunks) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    chunk_texts = []\n",
    "    \n",
    "    for audio_chunk in audio_chunks:\n",
    "        chunk_texts.append(audio_chunk['result'].text)\n",
    "    \n",
    "    return \" \".join(chunk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1642b5aa-ae4c-4931-9e54-8521f2db2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunk(model, audio_chunks, audio):\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    #_, probs = model.detect_language(mel)\n",
    "    #print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    \n",
    "    last_chunk = audio_chunks[:-1]\n",
    "    \n",
    "    if len(last_chunk) == 0:\n",
    "        last_chunk = None\n",
    "    else:\n",
    "        last_chunk = last_chunk[0]\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(\n",
    "        language=\"en\",\n",
    "        prompt=\"\" if not last_chunk else last_chunklast_chunk['result'].text\n",
    "        #suppress_tokens\n",
    "    )\n",
    "    \n",
    "    result = whisper.decode(model, mel, options)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f8dd91-5bd2-4740-82fa-53f6572a5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(chunk, state, delay):\n",
    "    print(\"@transcribe\")\n",
    "    \n",
    "    global model\n",
    "    global audio_chunks\n",
    "   \n",
    "    # Why -1?\n",
    "    #time.sleep(delay - 1)\n",
    "    \n",
    "    time.sleep(delay)\n",
    "    print(f\"delaying: {delay}\")\n",
    "    \n",
    "    #for n in range(round(delay * 10)):\n",
    "        #print(f\".\", end='', flush=True)\n",
    "        #time.sleep(n/10)\n",
    "    \n",
    "    print(\"Transcribing chunk...\")\n",
    "    \n",
    "    result = transcribe_chunk(model, audio_chunks, chunk)\n",
    "    \n",
    "    audio_chunks.append({\n",
    "        'chunk': chunk,\n",
    "        'result': result\n",
    "    })\n",
    "    \n",
    "    transcript = get_full_transcript(model, audio_chunks)\n",
    "\n",
    "    state['transcription'] = transcript\n",
    "    \n",
    "    print(\"=====================================\")\n",
    "    print(result.text)\n",
    "    print(\"-------------------------------------\")\n",
    "    print(transcript)\n",
    "    print()\n",
    "\n",
    "    return state['transcription'], state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8cce2d6-202f-47ca-864b-77bbf5178aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gradio/inputs.py:88: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/blocks.py:154: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://12534.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://12534.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@transcribe\n",
      "delaying: 3\n",
      "Transcribing chunk...\n",
      "you\n",
      "\n",
      "=====================================\n",
      "you\n",
      "-------------------------------------\n",
      "you\n",
      "\n",
      "@transcribe\n",
      "delaying: 3\n",
      "Transcribing chunk...\n",
      "Okay, so we're going to try and make sure that we're going to get the right amount of\n",
      "\n",
      "=====================================\n",
      "Okay, so we're going to try and make sure that we're going to get the right amount of\n",
      "-------------------------------------\n",
      "you Okay, so we're going to try and make sure that we're going to get the right amount of\n",
      "\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f5455695090>,\n",
       " 'http://127.0.0.1:7863/',\n",
       " 'https://12534.gradio.app')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"two-way-speech\"\n",
    "description = \"A demo of two-way-speech\"\n",
    "\n",
    "#model_size = gr.Dropdown(label=\"Model size\", choices=['base', 'tiny', 'small', 'medium', 'large'], value=DEFAULT_MODEL_SIZE)\n",
    "\n",
    "delay_slider = gr.inputs.Slider(minimum=1, maximum=5, default=DEFAULT_DELAY, label=\"Rate of transcription\")\n",
    "\n",
    "transcription_tb = gr.Textbox(label=\"Transcription\", lines=10, max_lines=500)\n",
    "\n",
    "state = gr.State({\"transcription\": \"\"})\n",
    "\n",
    "gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True),\n",
    "        state,\n",
    "        delay_slider,\n",
    "    ],\n",
    "    outputs=[\n",
    "        transcription_tb,\n",
    "        state\n",
    "    ],\n",
    "    live=True,\n",
    "    allow_flagging='never',\n",
    "    title=title,\n",
    "    description=description,\n",
    ").launch(\n",
    "    # enable_queue=True,\n",
    "    debug=True,\n",
    "    share=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e46345-e6d4-4b09-89a6-81794c8df54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': '/tmp/audiobwbn4hv6.wav',\n",
       "  'result': DecodingResult(audio_features=tensor([[-0.6465, -0.8188, -0.3569,  ...,  0.5605, -0.9712,  0.6470],\n",
       "          [-0.2820, -0.8750,  0.4353,  ...,  0.7393, -0.2871,  0.5088],\n",
       "          [ 0.1086, -0.6426,  0.1007,  ...,  0.6079, -0.2150,  0.2878],\n",
       "          ...,\n",
       "          [-0.2246, -0.9438,  0.3901,  ...,  0.3325, -0.5723,  0.2727],\n",
       "          [-0.6548, -0.7056,  0.1461,  ...,  0.3655, -0.2693,  0.1015],\n",
       "          [-0.7979, -0.5146,  0.4526,  ...,  0.2416, -1.0088, -1.0889]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50364, 291, 50464], text='you', avg_logprob=-0.9292147159576416, no_speech_prob=0.9420355558395386, temperature=0.0, compression_ratio=0.2727272727272727)},\n",
       " {'chunk': '/tmp/audioyt9ozeqg.wav',\n",
       "  'result': DecodingResult(audio_features=tensor([[-1.4961, -0.3057, -0.6582,  ..., -0.9312,  0.4146, -0.4819],\n",
       "          [-1.7656, -0.3223,  0.3740,  ..., -0.5493, -0.0768, -0.3401],\n",
       "          [-0.3142, -0.9048,  0.5200,  ..., -0.1175, -0.4988, -0.9707],\n",
       "          ...,\n",
       "          [-0.3298, -1.9268,  0.1274,  ...,  1.0068, -0.6450,  0.5474],\n",
       "          [-0.7363, -1.6572,  0.0833,  ...,  0.6055, -0.2322,  0.2595],\n",
       "          [-1.4971, -1.1914,  0.8594,  ...,  0.8369, -1.8311, -0.9712]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50364, 1033, 11, 370, 321, 434, 516, 281, 853, 293, 652, 988, 300, 321, 434, 516, 281, 483, 264, 558, 2372, 295, 50714], text=\"Okay, so we're going to try and make sure that we're going to get the right amount of\", avg_logprob=-1.028960148493449, no_speech_prob=0.13243550062179565, temperature=0.0, compression_ratio=1.1486486486486487)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_chunks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
