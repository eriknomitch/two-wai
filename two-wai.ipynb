{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe5a50-3bea-4015-8b9e-e1f906d68180",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580c2f95-95dd-43c7-a36e-ddc931bc34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d029a76d-7515-4f5a-8182-9c2561816ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if INSTALL:\n",
    "    ! pip install -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ed0d0e-6201-40b0-8f68-fb8b1237007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41e50c-7c77-4083-96c0-0e26c92fa733",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fbbe4a-da6a-4679-ac1e-2a84303f1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_SIZE = \"tiny\"\n",
    "DEFAULT_DELAY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80132694-5624-43f5-8a0e-343c4bc75c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import whisper\n",
    "from whisper import tokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac72ba7-562e-4119-8b60-68e0274eac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_size = DEFAULT_MODEL_SIZE\n",
    "model = whisper.load_model(current_size)\n",
    "audio_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1832983e-3d2d-46ea-b3c8-e8327f3b1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript(model, audio_chunks):\n",
    "    if len(audio_chunks) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    chunk_texts = []\n",
    "    \n",
    "    for audio_chunk in audio_chunks:\n",
    "        chunk_texts.append(audio_chunk['result'].text)\n",
    "    \n",
    "    return \" \".join(chunk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1642b5aa-ae4c-4931-9e54-8521f2db2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunk(model, audio_chunks, audio):\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    \n",
    "    last_chunk = audio_chunks[:-1]\n",
    "    \n",
    "    if len(last_chunk) == 0:\n",
    "        last_chunk = None\n",
    "    else:\n",
    "        last_chunk = last_chunk[0]\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(\n",
    "        language=\"en\",\n",
    "        #prompt=\"\" if not last_chunk else last_chunklast_chunk['result'].text\n",
    "        #suppress_tokens\n",
    "    )\n",
    "    \n",
    "    return whisper.decode(model, mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f8dd91-5bd2-4740-82fa-53f6572a5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(chunk, state, delay):\n",
    "    print(\"@transcribe\")\n",
    "    \n",
    "    global model\n",
    "    global audio_chunks\n",
    "   \n",
    "    # Why -1?\n",
    "    #time.sleep(delay - 1)\n",
    "    \n",
    "    state['debug'] += \"@transcribe \"\n",
    "    \n",
    "    time.sleep(delay - 1)\n",
    "    print(f\"delaying: {delay}\")\n",
    "    \n",
    "    #for n in range(round(delay * 10)):\n",
    "        #print(f\".\", end='', flush=True)\n",
    "        #time.sleep(n/10)\n",
    "    \n",
    "    print(\"Transcribing chunk...\")\n",
    "    \n",
    "    result = transcribe_chunk(model, audio_chunks, chunk)\n",
    "    \n",
    "    audio_chunks.append({\n",
    "        'chunk': chunk,\n",
    "        'result': result\n",
    "    })\n",
    "    \n",
    "    transcript = get_full_transcript(model, audio_chunks)\n",
    "\n",
    "    state['transcription'] = transcript\n",
    "    \n",
    "    print(\"=====================================\")\n",
    "    print(result.text)\n",
    "    print(\"-------------------------------------\")\n",
    "    print(transcript)\n",
    "    print()\n",
    "\n",
    "    return state['transcription'], state['debug'], state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cce2d6-202f-47ca-864b-77bbf5178aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gradio/inputs.py:88: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/blocks.py:154: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://29396.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://29396.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@transcribe\n",
      "delaying: 5\n",
      "Transcribing chunk...\n",
      "Detected language: en\n",
      "=====================================\n",
      "you\n",
      "-------------------------------------\n",
      "you\n",
      "\n",
      "@transcribe\n",
      "delaying: 5\n",
      "Transcribing chunk...\n",
      "Detected language: en\n",
      "=====================================\n",
      "Okay, see if debug updates is printing.\n",
      "-------------------------------------\n",
      "you Okay, see if debug updates is printing.\n",
      "\n",
      "@transcribe\n",
      "delaying: 5\n",
      "Transcribing chunk...\n",
      "Detected language: en\n",
      "=====================================\n",
      "There we go. Watch what we got. A weird one. Oh well.\n",
      "-------------------------------------\n",
      "you Okay, see if debug updates is printing. There we go. Watch what we got. A weird one. Oh well.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = \"two-way-speech\"\n",
    "description = \"A demo of two-way-speech\"\n",
    "\n",
    "delay_slider = gr.inputs.Slider(minimum=1, maximum=5, default=DEFAULT_DELAY, label=\"Rate of transcription\")\n",
    "\n",
    "transcription_tb = gr.Textbox(label=\"Transcription\", lines=10, max_lines=500)\n",
    "\n",
    "debug_tb = gr.Textbox(label=\"Debug\", lines=50, max_lines=200)\n",
    "\n",
    "state = gr.State({\"transcription\": \"\", \"debug\": \"\"})\n",
    "\n",
    "gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True),\n",
    "        state,\n",
    "        delay_slider,\n",
    "    ],\n",
    "    outputs=[\n",
    "        transcription_tb,\n",
    "        debug_tb,\n",
    "        state\n",
    "    ],\n",
    "    live=True,\n",
    "    allow_flagging='never',\n",
    "    title=title,\n",
    "    description=description,\n",
    ").launch(\n",
    "    # enable_queue=True,\n",
    "    debug=True,\n",
    "    share=True\n",
    "  )\n",
    "\n",
    "\"Started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e8d6b-a009-40e0-b5f8-42b432bd683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_full_transcript(model, audio_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08972c40-ea68-4eb1-9493-bff30d22d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def display_audio_chunk(index):\n",
    "    global audio_chunks\n",
    "    chunk = audio_chunks[index]['chunk']\n",
    "    return IPython.display.Audio(chunk)\n",
    "\n",
    "def display_audio_chunks():\n",
    "    global audio_chunks\n",
    "    for chunk in audio_chunks:\n",
    "        IPython.display.display(IPython.display.Audio(chunk['chunk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec0e7d-2b86-43d8-9345-9b9dbae19480",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio_chunks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
