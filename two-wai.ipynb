{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e4275-6cca-4f99-8750-9458c8a7df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a874f037-5d10-48df-b8f6-1fbf7d759575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(audio_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884ea5c-cacd-4a6f-b8c8-04204b7ebdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample(audio_chunks, 16000/48000, 'sinc_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe5a50-3bea-4015-8b9e-e1f906d68180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029a76d-7515-4f5a-8182-9c2561816ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#\n",
    "#if not os.path.exists(\"INSTALLED\"):\n",
    "#    ! pip install -r requirements.txt > /dev/null && touch INSTALLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed0d0e-6201-40b0-8f68-fb8b1237007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ipdb import set_trace\n",
    "except ImportError:\n",
    "    ! pip install -r requirements.txt > /dev/null && touch INSTALLED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debb73a-e25e-472a-9ef6-8b78a493d994",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8b6c2-2e07-4f58-a5d9-2178fba0c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_SIZE = \"base\"\n",
    "DEFAULT_DELAY = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41e50c-7c77-4083-96c0-0e26c92fa733",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80132694-5624-43f5-8a0e-343c4bc75c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import traceback\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gradio as gr\n",
    "import whisper\n",
    "from whisper import tokenizer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from samplerate.converters import resample\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "%load_ext gradio\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d36b4-1b62-4b75-b18c-8c3dce9f7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(DEFAULT_MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0d838-c530-4ba8-8536-cf95cadc14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks = False\n",
    "raw_chunks = False\n",
    "audio_sr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea339469-2857-4531-9003-aef755f846fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_session():\n",
    "    global audio_chunks\n",
    "    global raw_chunks\n",
    "    global audio_sr\n",
    "    \n",
    "    !rm /tmp/audio*.wav /tmp/chunks*.wav\n",
    "    \n",
    "    audio_chunks = np.array([], dtype='int16')\n",
    "    raw_chunks = []\n",
    "    audio_sr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08972c40-ea68-4eb1-9493-bff30d22d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def display_audio_chunk(index):\n",
    "    global audio_chunks\n",
    "    chunk = audio_chunks[index]['chunk']\n",
    "    return IPython.display.Audio(chunk)\n",
    "\n",
    "def display_audio_chunks():\n",
    "    global audio_chunks\n",
    "    for chunk in audio_chunks:\n",
    "        IPython.display.display(IPython.display.Audio(chunk['chunk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832983e-3d2d-46ea-b3c8-e8327f3b1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript(model, audio_chunks):\n",
    "    if len(audio_chunks) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    chunk_texts = []\n",
    "    \n",
    "    for audio_chunk in audio_chunks:\n",
    "        chunk_texts.append(audio_chunk['result'].text)\n",
    "    \n",
    "    return \" \".join(chunk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46591f2f-9528-4317-b7d5-f046b8325cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_audio_chunks_to_wav(chunks, sr, filename):\n",
    "    scaled = np.int16(chunks/np.max(np.abs(chunks)) * 32767)\n",
    "    wavfile.write(filename, sr, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eafcf95-430b-400f-b291-ac6e3b08340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mediainfo /tmp/audio02qqtl0t.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642b5aa-ae4c-4931-9e54-8521f2db2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunk(model, audio_chunks, audio):\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    #_, probs = model.detect_language(mel)\n",
    "    #print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    \n",
    "    last_chunk = audio_chunks[:-1]\n",
    "    \n",
    "    if len(last_chunk) == 0:\n",
    "        last_chunk = None\n",
    "    else:\n",
    "        last_chunk = last_chunk[0]\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(\n",
    "        language=\"en\",\n",
    "        prompt=\"\" if not last_chunk else last_chunk['result'].text\n",
    "        #suppress_tokens\n",
    "    )\n",
    "    \n",
    "    return whisper.decode(model, mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a6449-1e72-485d-bf69-5080853052d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    return datetime.utcnow().isoformat(sep=' ', timespec='milliseconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573127d-a09a-4be8-b673-f0f138146539",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c8341-23f3-4537-9f43-9c3a6ccad198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = resample(audio_chunks, 16000/audio_sr, 'sinc_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41a6f8-f742-450b-879e-98ad033b35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = whisper.pad_or_trim(audio_chunks.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31307b-dd1a-4eaa-a52d-8920937d1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel = whisper.log_mel_spectrogram(a).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14670dfd-fea9-442d-b26e-baed0994e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = whisper.DecodingOptions(language=\"en\")\n",
    "#d = whisper.decode(model, mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0def98-cde5-42b9-be22-1b7611a3af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript():\n",
    "    global audio_chunks\n",
    "    global audio_sr\n",
    "    \n",
    "    chunk_path = f\"/tmp/chunks_{len(audio_chunks)}.wav\"\n",
    "    \n",
    "    write_audio_chunks_to_wav(audio_chunks, audio_sr, chunk_path)\n",
    "    \n",
    "    audio = whisper.load_audio(chunk_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    #_, probs = model.detect_language(mel)\n",
    "    #print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(\n",
    "        language=\"en\"\n",
    "        #prompt=\"\" if not last_chunk else last_chunk['result'].text\n",
    "        #suppress_tokens\n",
    "    )\n",
    "    \n",
    "    return whisper.decode(model, mel, options)\n",
    "    \n",
    "    #local_chunks = audio_chunks.copy()\n",
    "    #chunks_transformed = local_chunks.astype(np.float32)\n",
    "    #chunks_transformed = local_chunks.astype(np.float32) / 32768.0\n",
    "    \n",
    "    #chunks_transformed = resample(local_chunks, 16000/audio_sr, 'sinc_best')\n",
    "    \n",
    "    result = model.transcribe(chunks_transformed, language=\"English\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc3f92-5e71-48ef-b9f4-ca8f801c7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript():\n",
    "    global audio_chunks\n",
    "    global audio_sr\n",
    "    \n",
    "    chunk_path = f\"/tmp/chunks_{len(audio_chunks)}.wav\"\n",
    "    \n",
    "    write_audio_chunks_to_wav(audio_chunks, audio_sr, chunk_path)\n",
    "    \n",
    "    result = model.transcribe(chunk_path, language=\"English\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908a240-4d5e-401e-9de4-ac41887784fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(chunk, state, delay):\n",
    "    #print(get_timestamp())\n",
    "    \n",
    "    #state['debug'] += f\"{get_timestamp()}:\\n\"\n",
    "    state['debug'] += f\".\"\n",
    "    \n",
    "    #print(chunk)\n",
    "    #print(np.shape(chunk[1]))\n",
    "    \n",
    "    global audio_sr\n",
    "    global audio_chunks\n",
    "    global raw_chunks\n",
    "    \n",
    "    audio_sr = chunk[0]\n",
    "    \n",
    "    try:\n",
    "        audio_chunks = np.append(audio_chunks, np.array(chunk[1], dtype='int16'))\n",
    "        raw_chunks.append(chunk[1])\n",
    "        print(chunk[1].dtype)\n",
    "    except Exception:\n",
    "        error_message = traceback.format_exc()\n",
    "        print(error_message)\n",
    "    \n",
    "    transcript = get_full_transcript()\n",
    "    \n",
    "    #print(transcript)\n",
    "    #print()\n",
    "    #print(transcript[\"text\"])\n",
    "    #print()\n",
    "\n",
    "    state['transcription'] = transcript['text']\n",
    "    \n",
    "    return state['transcription'], state['debug'], state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3a818-e2fb-4cb2-8cdf-9a1e5e5ede22",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e0535-e110-4fb4-9b02-2b7806fef1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_session()\n",
    "\n",
    "print(audio_sr)\n",
    "audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cce2d6-202f-47ca-864b-77bbf5178aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"two-wai\"\n",
    "description = \"desc\"\n",
    "\n",
    "delay_slider = gr.Slider(minimum=0, maximum=10, value=DEFAULT_DELAY, label=\"Rate of transcription\")\n",
    "\n",
    "transcription_tb = gr.Textbox(label=\"Transcription\", lines=5, max_lines=500)\n",
    "\n",
    "debug_tb = gr.Textbox(label=\"Debug\", lines=5, max_lines=200)\n",
    "\n",
    "# FIX:\n",
    "state = gr.State({\"transcription\": \"\", \"debug\": \"\", \"audio_chunks\": np.array([]), \"audio_sr\": 48000})\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        # The format the audio file is converted to before being passed into the prediction function. \"numpy\" converts the audio to a tuple consisting of: (int sample rate, numpy.array for the data),\n",
    "        # \"filepath\" passes a str path to a temporary file containing the audio.\n",
    "        gr.Audio(source=\"microphone\", type=\"numpy\", streaming=True),\n",
    "        state,\n",
    "        delay_slider,\n",
    "    ],\n",
    "    outputs=[\n",
    "        transcription_tb,\n",
    "        debug_tb,\n",
    "        state\n",
    "    ],\n",
    "    live=True,\n",
    "    allow_flagging='auto',\n",
    "    title=title,\n",
    "    description=description,\n",
    ").launch(\n",
    "    enable_queue=True,\n",
    "    debug=True,\n",
    "    share=True,\n",
    "    inline=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c59cd-c62a-4440-923e-6aed1c54f490",
   "metadata": {},
   "source": [
    "# audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ce60d-84a0-4725-a64d-66a7acaf6910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba34f35-d082-48e4-b735-cca2c523fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124ceb1-406e-46cf-acb4-3150e6e87c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(np.array(raw_chunks).astype(np.float32), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5b76d-e253-48eb-bfab-10884966d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.avgerage(audio_chunks.astype(np.float32)  / 32768.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9f137-ef4f-408e-ae91-a6ed2125ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transcribe(audio_chunks.astype(np.float32), language=\"English\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af511c-f832-4bca-88b7-e09fc9684a5e",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe83fa9-9dce-493d-8084-b19fc6f842e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26c5ea-16f5-42a7-8be2-5f27a3fa8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f3d2d-67f8-478b-a8d1-937dc391f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(audio_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938062d6-a750-41a3-8bea-22a8756f8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(audio_chunks) > 0:\n",
    "    transcript = get_full_transcript(model, audio_chunks)\n",
    "    print(transcript)\n",
    "    display_audio_chunks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
