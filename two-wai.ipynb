{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe5a50-3bea-4015-8b9e-e1f906d68180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029a76d-7515-4f5a-8182-9c2561816ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"INSTALLED\"):\n",
    "    ! pip install -r requirements.txt > /dev/null && touch INSTALLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed0d0e-6201-40b0-8f68-fb8b1237007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debb73a-e25e-472a-9ef6-8b78a493d994",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8b6c2-2e07-4f58-a5d9-2178fba0c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_SIZE = \"base\"\n",
    "DEFAULT_DELAY = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41e50c-7c77-4083-96c0-0e26c92fa733",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80132694-5624-43f5-8a0e-343c4bc75c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import copy from copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gradio as gr\n",
    "import whisper\n",
    "from whisper import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f6eb0-f57b-4c54-8602-d5f2a9e5798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac72ba7-562e-4119-8b60-68e0274eac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_size = DEFAULT_MODEL_SIZE\n",
    "model = whisper.load_model(current_size)\n",
    "audio_chunks = []\n",
    "audio_stream = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08972c40-ea68-4eb1-9493-bff30d22d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def display_audio_chunk(index):\n",
    "    global audio_chunks\n",
    "    chunk = audio_chunks[index]['chunk']\n",
    "    return IPython.display.Audio(chunk)\n",
    "\n",
    "def display_audio_chunks():\n",
    "    global audio_chunks\n",
    "    for chunk in audio_chunks:\n",
    "        IPython.display.display(IPython.display.Audio(chunk['chunk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832983e-3d2d-46ea-b3c8-e8327f3b1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_transcript(model, audio_chunks):\n",
    "    if len(audio_chunks) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    chunk_texts = []\n",
    "    \n",
    "    for audio_chunk in audio_chunks:\n",
    "        chunk_texts.append(audio_chunk['result'].text)\n",
    "    \n",
    "    return \" \".join(chunk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642b5aa-ae4c-4931-9e54-8521f2db2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunk(model, audio_chunks, audio):\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    #_, probs = model.detect_language(mel)\n",
    "    #print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    \n",
    "    last_chunk = audio_chunks[:-1]\n",
    "    \n",
    "    if len(last_chunk) == 0:\n",
    "        last_chunk = None\n",
    "    else:\n",
    "        last_chunk = last_chunk[0]\n",
    "    \n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(\n",
    "        language=\"en\",\n",
    "        prompt=\"\" if not last_chunk else last_chunk['result'].text\n",
    "        #suppress_tokens\n",
    "    )\n",
    "    \n",
    "    return whisper.decode(model, mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8dd91-5bd2-4740-82fa-53f6572a5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(chunk, state, delay):\n",
    "    #time.sleep(delay)\n",
    "    print(\"@transcribe\")\n",
    "    \n",
    "    global model\n",
    "    global audio_chunks\n",
    "   \n",
    "    print(f\"delaying: {delay}\")\n",
    "    \n",
    "    for n in range(round(delay * 10)):\n",
    "        print(f\".\", end='', flush=True)\n",
    "        time.sleep(delay/10)\n",
    "    \n",
    "    print(\"Transcribing chunk...\")\n",
    "    \n",
    "    start = timer()\n",
    "    result = transcribe_chunk(model, audio_chunks, chunk)\n",
    "    end = timer()\n",
    "    print(timedelta(seconds=end-start))\n",
    "    \n",
    "    #if result['\n",
    "    \n",
    "    audio_chunks.append({\n",
    "        'chunk': chunk,\n",
    "        'result': result\n",
    "    })\n",
    "    \n",
    "    transcript = get_full_transcript(model, audio_chunks)\n",
    "\n",
    "    state['debug'] += \"@transcribe \"\n",
    "    state['transcription'] = transcript\n",
    "    \n",
    "    print(\"=====================================\")\n",
    "    print(result.text)\n",
    "    print(\"-------------------------------------\")\n",
    "    print(transcript)\n",
    "    print()\n",
    "\n",
    "    return state['transcription'], state['debug'], state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908a240-4d5e-401e-9de4-ac41887784fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(chunk, state, delay):\n",
    "    print(datetime.utcnow().isoformat(sep=' ', timespec='milliseconds'))\n",
    "    global audio_stream\n",
    "    \n",
    "    if not audio_stream:\n",
    "        audio_stream = copy(chunk)\n",
    "    else:\n",
    "        sr = chunk[0]\n",
    "        samples = chunk[1]\n",
    "\n",
    "        audio_stream = (sr, np.concatenate(audio_stream[1], samples)\n",
    "    \n",
    "    print(audio_stream[2].size)\n",
    "    \n",
    "    return state['transcription'], state['debug'], state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3a818-e2fb-4cb2-8cdf-9a1e5e5ede22",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cce2d6-202f-47ca-864b-77bbf5178aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"two-wai\"\n",
    "description = \"desc\"\n",
    "\n",
    "delay_slider = gr.Slider(minimum=0, maximum=10, value=DEFAULT_DELAY, label=\"Rate of transcription\")\n",
    "\n",
    "transcription_tb = gr.Textbox(label=\"Transcription\", lines=10, max_lines=500)\n",
    "\n",
    "debug_tb = gr.Textbox(label=\"Debug\", lines=10, max_lines=200)\n",
    "\n",
    "state = gr.State({\"transcription\": \"\", \"debug\": \"\"})\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        # The format the audio file is converted to before being passed into the prediction function. \"numpy\" converts the audio to a tuple consisting of: (int sample rate, numpy.array for the data),\n",
    "        # \"filepath\" passes a str path to a temporary file containing the audio.\n",
    "        gr.Microphone(type=\"filepath\", streaming=True),\n",
    "        state,\n",
    "        delay_slider,\n",
    "    ],\n",
    "    outputs=[\n",
    "        transcription_tb,\n",
    "        debug_tb,\n",
    "        state\n",
    "    ],\n",
    "    live=True,\n",
    "    allow_flagging='never',\n",
    "    title=title,\n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265b9f4-2735-43e9-a0cf-f8926ff37d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(\n",
    "    enable_queue=True,\n",
    "    debug=True,\n",
    "    share=True,\n",
    "    inline=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af511c-f832-4bca-88b7-e09fc9684a5e",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938062d6-a750-41a3-8bea-22a8756f8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(audio_chunks) > 0:\n",
    "    transcript = get_full_transcript(model, audio_chunks)\n",
    "    print(transcript)\n",
    "    display_audio_chunks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
